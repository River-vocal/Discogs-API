{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pip install python3-discogs-client\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "# pip install openpyxl # convert dataframe to xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import discogs_client\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Set up discogs client](https://python3-discogs-client.readthedocs.io/en/latest/authentication.html)\n",
    "* API_KEY\n",
    "* user agent\n",
    "    * A User-Agent is required for Discogs API requests, as it identifies your application to the Discogs servers.\n",
    "* client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'YOUR API_KEY' # \n",
    "user_agent = 'discogs_project/1.0'  # A User-Agent is required for Discogs API requests, as it identifies your application to the Discogs servers.\n",
    "client_id = 108475\n",
    "d = discogs_client.Client(user_agent, user_token=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 108475 is the artist id for Greg Phillinganes.\n",
    "greg = d.artist(client_id)\n",
    "\n",
    "# All the releases/masters related to Greg Phillinganes.\n",
    "greg_rel = greg.releases\n",
    "# The release list can be paginated, 22 pages in total.\n",
    "# greg_rel_page0 = greg_rel.page(0)\n",
    "# greg_rel_page1 = greg_rel.page(1)\n",
    "# greg_rel_page2 = greg_rel.page(2)\n",
    "# greg_rel_page3 = greg_rel.page(3)\n",
    "# greg_rel_page4 = greg_rel.page(4)\n",
    "# greg_rel_page5 = greg_rel.page(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def copy_data(rel_entry):\n",
    "    # We need the following line to force the program to copy all the data of the release.\n",
    "    # Without it, the size of the resultant dict will be only 12. This is the most painful part.\n",
    "    dum = rel_entry.url\n",
    "    # Set the time value to 0.95 or larger, if received \"too many requests\" error from server.\n",
    "    time.sleep(0.9)\n",
    "    return rel_entry.data\n",
    "\n",
    "# # Each entry of the master_list is a version_list.\n",
    "# # A version_list contains every version of a master release.\n",
    "# # Each entry of the version_list is a dict containing everything of a version(release/album).\n",
    "# # All versions -> version_list -> master_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(page):\n",
    "    start_time = time.time()\n",
    "    master_list_page = []\n",
    "    # greg_rel is the whole list, with 21 pages.\n",
    "    for cur_rel in page:\n",
    "        version_list = []\n",
    "        # Each release's type is either master or release\n",
    "        if cur_rel.data[\"type\"] == \"master\":\n",
    "            for rel_entry in cur_rel.versions:\n",
    "                version_list.append(copy_data(rel_entry))\n",
    "        else:\n",
    "            version_list.append(copy_data(cur_rel))\n",
    "            \n",
    "        \n",
    "        print(cur_rel.title)  # comment this line if you don't need detailed release names to be printed out.\n",
    "        master_list_page.append(version_list)\n",
    "    end_time = time.time()\n",
    "    print(end_time - start_time)\n",
    "    return master_list_page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected data\n",
    "\n",
    "### Performer Metadata\n",
    "Role, Category, Track Title, Track Artists,\tAlbum, Distributing Label, Release Year, Duration, Instruments, \tNumber of Featured Performers, UPC, Evidence(url), \n",
    "\n",
    "\n",
    "### Conditional Data\n",
    "Version(remix, radio, edit...), Additional Credit(producer, arranger, conductor), Year of Recording\tCountry of Recording(blank if same release year), Country of Release, Percentage of FP share, \n",
    "\n",
    "### Optional Data\n",
    "ISRC, Genre, Format, Catalog #, Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Releases:\n",
    "    -Release 1:\n",
    "        -tracklist\n",
    "            -track 1\n",
    "                -extraartists\n",
    "                    -greg\n",
    "                -......\n",
    "            -track 2\n",
    "                -extraartists\n",
    "                    -greg\n",
    "                    -......\n",
    "            -track 3\n",
    "                -extraartists\n",
    "                    -others\n",
    "                    -......\n",
    "            ...\n",
    "        -id\n",
    "        -year\n",
    "        -...\n",
    "```\n",
    "\n",
    "* Convert master data from list of dict to dataframe. \n",
    "* Drop some useless columns. \n",
    "* Get artists name of each releases\n",
    "* Get role of our client if there is such information. If there is no such information, leave the cell 'unknown'\n",
    "\n",
    "## Note: \n",
    "1. Roles might be displayed in extraartists column of releases dataframe or hidden deeper in tracklist column. \n",
    "2. The roles in artists column are always empty, so we extract role information from the extraartists fields.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Dataframe  --> Extract credits from tracks\n",
    "\n",
    "> The track data comes from the tracklist column in each release\n",
    "\n",
    "> Basiclly, each release has a different number of tracks, and each track has different extra artists. The main idea is to keep all the tracks first and then drop the ones with extra artists that do not include our client (GP). \n",
    "\n",
    "> In the process, if the client has credits in certain tracks, we get the corresponding roles. If there are no additional artists, we keep the track as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join release data into each track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After we get all tracks, we can combine the release data to each track based on the same release id\n",
    "\n",
    "\n",
    "## Note: \n",
    "1. There are some overlapped data in the dataframe, for instance, tracklist, role, artists, extraartists. \n",
    "2. If both track_role and release_role are 'unknown' which means there is no role information found in original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(page, pageNum):\n",
    "    release_df = pd.DataFrame()\n",
    "    for master in page:\n",
    "        release_df = pd.concat([release_df, pd.DataFrame(master)], ignore_index=True)\n",
    "        \n",
    "    # drop some useless columns\n",
    "    release_df = release_df.drop(['videos', 'labels', 'status','stats', 'companies', 'format', 'community', 'images', 'artists_sort'], axis = 1)\n",
    "    \n",
    "    # extract artists name and id from artists dictionary\n",
    "    release_df.artists = [[(i['name'], i['id']) if i != '' else i for i in d ] for d in release_df.artists]\n",
    "    \n",
    "    # extract formats from formats dictionary\n",
    "    release_df.formats = [[i['name'] for i in d ]for d in release_df.formats ]\n",
    "    \n",
    "    # get roles if there is such information from releases\n",
    "    cleaned_release_roles = []\n",
    "    for extraartists in release_df.extraartists:\n",
    "        role = []\n",
    "        if extraartists:\n",
    "            for extraartist in extraartists:\n",
    "                if extraartist['id'] == 108475:\n",
    "                    role.append(extraartist['role'])\n",
    "        else:\n",
    "            role.append('unknown')\n",
    "        cleaned_release_roles.append(role)\n",
    "    release_df['release_role'] = cleaned_release_roles\n",
    "    release_df['release_role'] = [';'.join(map(str, l)) for l in release_df.release_role]\n",
    "    \n",
    "    # extract tracks from all releases\n",
    "    tracks_df = pd.DataFrame([dict(**{'release_id':rel_id}, **y) for rel_id, v in zip(release_df.id, release_df.tracklist.values) for y in v], )\n",
    "    tracks_df = tracks_df.replace(np.nan,'',regex=True)\n",
    "    \n",
    "    # get roles if there is such information from tracks\n",
    "\n",
    "    cleaned_roles = []\n",
    "    for extraartists in tracks_df.extraartists:\n",
    "        role = []\n",
    "        if extraartists:\n",
    "            for extraartist in extraartists:\n",
    "                if extraartist['id'] == 108475:\n",
    "                    role.append(extraartist['role'])\n",
    "        else:\n",
    "            role.append('unknown')\n",
    "        cleaned_roles.append(role)\n",
    "    tracks_df['track_role'] = cleaned_roles\n",
    "    tracks_df['track_role'] = [';'.join(map(str, l)) for l in tracks_df.track_role]\n",
    "    tracks_df = tracks_df.replace('',np.nan,regex=True)\n",
    "    tracks_df = tracks_df[tracks_df['track_role'].notna()]\n",
    "    \n",
    "    tracks_df.extraartists = tracks_df.extraartists.replace(np.nan,'',regex=True)\n",
    "    tracks_df['track_extraartists'] = [[(i['name'], i['id']) if i != '' else i for i in d ] for d in tracks_df.extraartists]\n",
    "    tracks_df['track_extraartists'] = [';'.join(map(str, l)) for l in tracks_df.track_extraartists]\n",
    "    \n",
    "    \n",
    "    tracks_df.artists = tracks_df.artists.replace(np.nan,'',regex=True)\n",
    "    tracks_df['track_artists'] = [[(i['name'], i['id']) if i != '' else i for i in d ] for d in tracks_df.artists]\n",
    "    tracks_df['track_artists'] = [';'.join(map(str, l)) for l in tracks_df.track_artists]\n",
    "    tracks_df = tracks_df.replace('',np.nan,regex=True)\n",
    "    tracks_df = tracks_df.drop(['extraartists', 'artists'], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    release_df = release_df.rename(columns={\"id\": \"release_id\"})\n",
    "    release_df = release_df.drop(['extraartists'], axis=1)\n",
    "    release_df = release_df.drop(['tracklist'], axis=1)\n",
    "    \n",
    "    \n",
    "    result_df = tracks_df.join(release_df.set_index('release_id'), on='release_id', lsuffix='_track', rsuffix='_release')\n",
    "    \n",
    "    idx = np.unique( result_df.index.values, return_index = True )[1]\n",
    "    result_df = result_df.iloc[idx]\n",
    "    \n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    result_df.to_csv('output/v3_sample_output_{1}_Page{0}.csv'.format(pageNum, greg.name)) \n",
    "    result_df.to_excel(\"output/v3_sample_output_{1}_Page{0}.xlsx\".format(pageNum, greg.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page  0\n",
      "Girl Talk\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(greg_rel\u001b[38;5;241m.\u001b[39mpages):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage \u001b[39m\u001b[38;5;124m'\u001b[39m, i)\n\u001b[0;32m----> 4\u001b[0m     page \u001b[38;5;241m=\u001b[39m \u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgreg_rel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     get_csv(page, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m Done\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mget_json\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cur_rel\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaster\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rel_entry \u001b[38;5;129;01min\u001b[39;00m cur_rel\u001b[38;5;241m.\u001b[39mversions:\n\u001b[0;32m---> 10\u001b[0m         version_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcopy_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_entry\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     version_list\u001b[38;5;241m.\u001b[39mappend(copy_data(cur_rel))\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mcopy_data\u001b[0;34m(rel_entry)\u001b[0m\n\u001b[1;32m      4\u001b[0m dum \u001b[38;5;241m=\u001b[39m rel_entry\u001b[38;5;241m.\u001b[39murl\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Set the time value to 0.95 or larger, if received \"too many requests\" error from server.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rel_entry\u001b[38;5;241m.\u001b[39mdata\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "master_list_pages = []\n",
    "for i in range(greg_rel.pages):\n",
    "    print('page ', i)\n",
    "    page = get_json(greg_rel.page(i))\n",
    "    get_csv(page, i + 1)\n",
    "    \n",
    "    print('page {0} Done'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
